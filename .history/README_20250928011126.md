# Comprehensive ML Pipeline on Heart Disease (UCI) â€” Starter Kit

**Date scaffolded:** 2025-09-28

This repo gives you a productionâ€‘ready scaffold to implement the full pipeline described in your spec:
Preprocessing â†’ PCA â†’ Feature Selection â†’ Supervised + Unsupervised â†’ Hyperparameter Tuning â†’ Export `.pkl` â†’ Streamlit UI â†’ (Optional) Ngrok.

---

## Quick Start

1) **Create env & install deps**
```bash
python -m venv .venv
 source .venv/bin/activate  # Windows (PowerShell): .venv\Scripts\Activate
pip install -r requirements.txt
```

2) **Add the dataset**
- Download the **Heart Disease UCI** CSV into `data/heart_disease.csv`.
  - Common columns expected (Cleveland-style):  
    `age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal,target`  
  - **Notes:** `?` values are treated as missing; original labels {0..4} are converted to binary inside the training script (`target > 0 â†’ 1`).

3) **Train baseline + tune + export**
```bash
python -m src.train_pipeline
```
- Metrics saved to `results/evaluation_metrics.txt`
- Best model saved to `models/final_model.pkl` (includes preprocessing pipeline).

4) **Run the Streamlit UI**
```bash
streamlit run ui/app.py
```
- Enter patient features, get prediction/probability.

---

## Repository Structure

```
Heart_Disease_Project/
â”œâ”€ data/
â”‚  â””â”€ heart_disease.csv     # (you add this)
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_data_preprocessing.ipynb
â”‚  â”œâ”€ 02_pca_analysis.ipynb
â”‚  â”œâ”€ 03_feature_selection.ipynb
â”‚  â”œâ”€ 04_supervised_learning.ipynb
â”‚  â”œâ”€ 05_unsupervised_learning.ipynb
â”‚  â””â”€ 06_hyperparameter_tuning.ipynb
â”œâ”€ models/
â”‚  â””â”€ final_model.pkl       # (auto-generated)
â”œâ”€ ui/
â”‚  â””â”€ app.py                # Streamlit app
â”œâ”€ deployment/
â”‚  â””â”€ ngrok_setup.txt
â”œâ”€ results/
â”‚  â””â”€ evaluation_metrics.txt
â”œâ”€ src/
â”‚  â”œâ”€ constants.py
â”‚  â”œâ”€ pipeline.py
â”‚  â”œâ”€ feature_selection.py
â”‚  â”œâ”€ supervised.py
â”‚  â”œâ”€ unsupervised.py
â”‚  â”œâ”€ tuning.py
â”‚  â””â”€ train_pipeline.py
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md
```
## Results (artifacts)

**ROC Curve**  
![ROC Curve](results/roc_curve.png)

**Confusion Matrix**  
![Confusion Matrix](results/confusion_matrix.png)

**PCA Cumulative Explained Variance**  
![PCA Explained Variance](results/pca_explained_variance.png)

**Streamlit UI**  
![App UI](results/ui_screenshot.png)

---

## Whatâ€™s included

- **Sklearn ColumnTransformer pipeline** with imputers, scaler, and oneâ€‘hot encoding.
- **PCA** helper (on scaled numeric features).
- **Feature selection** (RFE + Chiâ€‘Square + RF importance).
- **Baseline models**: Logistic Regression, Decision Tree, Random Forest, SVM.
- **Metrics**: Accuracy, Precision, Recall, F1, ROCâ€‘AUC + ROC curve data.
- **Clustering**: KMeans (elbow), Agglomerative (dendrogram) + ARI against labels.
- **Hyperparameter tuning** (GridSearchCV / RandomizedSearchCV) for RF and SVM.
- **Model export** with `joblib` (full pipeline, so UI can load and predict safely).
- **Streamlit UI** ready to run.

---

## Tips

- Keep **train/val/test** splits stable for fair comparisons.
- Check **class balance**; consider class weights or stratified splits.
- Track **random_state** for reproducibility.
- Use the notebooks for exploration; commit final logic into `/src` for production.

Good luck â€” ship it! ðŸš€